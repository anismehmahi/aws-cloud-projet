{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4385781e-259e-4d41-a57e-dced8170d6df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/fsspec/registry.py:272: UserWarning: Your installed version of s3fs is very old and known to cause\n",
      "severe performance issues, see also https://github.com/dask/dask/issues/10276\n",
      "\n",
      "To fix, you should specify a lower version bound on s3fs, or\n",
      "update the current installation.\n",
      "\n",
      "  warnings.warn(s3_msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "# Define S3 bucket and file details\n",
    "bucket = 'test-bucket-hattabi'\n",
    "data_key = 'processed/titanic.csv'\n",
    "prefix = 'train_test'\n",
    "data_location = 's3://{}/{}'.format(bucket, data_key)\n",
    "\n",
    "# Read data into a Pandas DataFrame\n",
    "df = pd.read_csv(data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76e988a3-f9cc-4699-89ae-4badac4baa1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Titre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass   Age  SibSp  Parch            Ticket  \\\n",
       "0              1         0       3  22.0      1      0         A/5 21171   \n",
       "1              2         1       1  38.0      1      0          PC 17599   \n",
       "2              3         1       3  26.0      0      0  STON/O2. 3101282   \n",
       "3              4         1       1  35.0      1      0            113803   \n",
       "4              5         0       3  35.0      0      0            373450   \n",
       "..           ...       ...     ...   ...    ...    ...               ...   \n",
       "886          887         0       2  27.0      0      0            211536   \n",
       "887          888         1       1  19.0      0      0            112053   \n",
       "888          889         0       3  19.0      1      2        W./C. 6607   \n",
       "889          890         1       1  26.0      0      0            111369   \n",
       "890          891         0       3  32.0      0      0            370376   \n",
       "\n",
       "        Fare  Sex_male  Embarked_Q  Embarked_S  Titre  \n",
       "0     7.2500         1           0           1      2  \n",
       "1    71.2833         0           0           0      3  \n",
       "2     7.9250         0           0           1      1  \n",
       "3    53.1000         0           0           1      3  \n",
       "4     8.0500         1           0           1      2  \n",
       "..       ...       ...         ...         ...    ...  \n",
       "886  13.0000         1           0           1      4  \n",
       "887  30.0000         0           0           1      1  \n",
       "888  23.4500         0           0           1      1  \n",
       "889  30.0000         1           0           0      2  \n",
       "890   7.7500         1           1           0      2  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a7186fb-c894-4ee0-82f7-8f9c6c4e01e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Survived         int64\n",
       "Pclass           int64\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Sex_male         int64\n",
       "Embarked_Q       int64\n",
       "Embarked_S       int64\n",
       "Titre            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "003e794e-f21e-4f64-989b-f07870cb194f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.drop(['Ticket'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6df9e385-c1ad-4608-9619-3a449379cbcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train,X_test,y_train,y_test = train_test_split(df.drop([\"Survived\", 'PassengerId'],axis=1),df[\"Survived\"], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d4568eab-5dc8-4bdb-a08d-9e936757067b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Combine the features and the target variable for train and test sets\n",
    "train_data = pd.concat([y_train,X_train], axis=1)\n",
    "test_data = pd.concat([y_test,X_test], axis=1)\n",
    "test_features = pd.concat([X_test], axis=1)\n",
    "\n",
    "# Save the datasets as CSV files\n",
    "train_data.to_csv('train.csv', index=False,header=False)\n",
    "test_data.to_csv('test.csv', index=False,header=False)\n",
    "test_features.to_csv('test_features.csv', index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8871e963-bab1-4391-8711-b9bf52005f61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload Successful\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "# Get the current SageMaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "# Get the S3 client\n",
    "s3 = boto3.client('s3')\n",
    "# Upload the train set\n",
    "s3.upload_file('train.csv', bucket, f'{prefix}/train.csv')\n",
    "# Upload the test set\n",
    "s3.upload_file('test.csv', bucket, f'{prefix}/test.csv')\n",
    "# Upload the test set features only\n",
    "s3.upload_file('test_features.csv', bucket, f'{prefix}/test_features.csv')\n",
    "print(\"Upload Successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81151cbf-4168-43ca-9b5a-6fab2263681d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Start a Training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ee73f5e-3938-4a73-86ce-8f07503bba70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import image_uris\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "container = image_uris.retrieve(\"xgboost\", region='eu-west-3', version='latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a38cc6a-a99f-4c46-8c9d-a058e6b3f316",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data=\"s3://{}/{}/train.csv\".format(bucket,prefix),content_type=\"csv\")\n",
    "s3_input_test = sagemaker.inputs.TrainingInput(s3_data=\"s3://{}/{}/test.csv\".format(bucket,prefix),content_type=\"csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "baa9852a-fde4-4bfe-86ea-23974f6404aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "xgb = sagemaker.estimator.Estimator(container,role,\n",
    "                                    instance_count=1,\n",
    "                                    instance_type='ml.m5.large',\n",
    "                                    output_path=\"s3://{}/output\".format(bucket),\n",
    "                                   sagemaker_session=sess)\n",
    "\n",
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        verbosity=1,\n",
    "                        objective='binary:logistic',\n",
    "                        num_round=40,\n",
    "                        eval_metric='auc')  # Add this line to monitor AUC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a472c4d6-9482-46d1-a7ff-cd6903992ecd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: xgboost-2024-01-19-12-41-43-265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-19 12:41:43 Starting - Starting the training job...\n",
      "2024-01-19 12:42:11 Starting - Preparing the instances for training.........\n",
      "2024-01-19 12:43:32 Downloading - Downloading input data......\n",
      "2024-01-19 12:44:27 Downloading - Downloading the training image..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2024-01-19:12:44:57:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2024-01-19:12:44:57:INFO] File size need to be processed in the node: 0.02mb. Available memory size in the node: 354.82mb\u001b[0m\n",
      "\u001b[34m[2024-01-19:12:44:57:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[12:44:57] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[12:44:57] 712x9 matrix with 6408 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2024-01-19:12:44:57:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[12:44:57] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[12:44:57] 179x9 matrix with 1611 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[12:44:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 8 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[0]#011train-auc:0.858772#011validation-auc:0.868983\u001b[0m\n",
      "\u001b[34m[12:44:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 10 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[1]#011train-auc:0.862907#011validation-auc:0.8713\u001b[0m\n",
      "\u001b[34m[12:44:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 8 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[2]#011train-auc:0.869126#011validation-auc:0.88314\u001b[0m\n",
      "\u001b[34m[12:44:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 10 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[3]#011train-auc:0.869916#011validation-auc:0.884041\u001b[0m\n",
      "\u001b[34m[12:44:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 14 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[4]#011train-auc:0.869655#011validation-auc:0.884685\u001b[0m\n",
      "\u001b[34m[12:44:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 10 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[5]#011train-auc:0.870046#011validation-auc:0.88462\u001b[0m\n",
      "\u001b[34m[12:44:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 20 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[6]#011train-auc:0.870063#011validation-auc:0.884363\u001b[0m\n",
      "\u001b[34m[12:44:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 18 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[7]#011train-auc:0.867365#011validation-auc:0.881274\u001b[0m\n",
      "\u001b[34m[12:44:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 16 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[8]#011train-auc:0.867382#011validation-auc:0.881274\u001b[0m\n",
      "\u001b[34m[12:44:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 6 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[9]#011train-auc:0.873521#011validation-auc:0.887452\u001b[0m\n",
      "\u001b[34m[12:44:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 12 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[10]#011train-auc:0.873975#011validation-auc:0.88758\u001b[0m\n",
      "\u001b[34m[12:44:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 8 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[11]#011train-auc:0.87516#011validation-auc:0.887774\u001b[0m\n",
      "\u001b[34m[12:44:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[12]#011train-auc:0.882316#011validation-auc:0.895302\u001b[0m\n",
      "\u001b[34m[12:44:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 8 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[13]#011train-auc:0.882799#011validation-auc:0.897233\u001b[0m\n",
      "\u001b[34m[12:44:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 22 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[14]#011train-auc:0.882799#011validation-auc:0.897233\u001b[0m\n",
      "\u001b[34m[12:44:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 24 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[15]#011train-auc:0.882799#011validation-auc:0.897233\u001b[0m\n",
      "\u001b[34m[12:44:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 24 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[16]#011train-auc:0.882799#011validation-auc:0.897233\u001b[0m\n",
      "\u001b[34m[12:44:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 24 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[17]#011train-auc:0.882799#011validation-auc:0.897233\u001b[0m\n",
      "\u001b[34m[12:44:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 24 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[18]#011train-auc:0.882799#011validation-auc:0.897233\u001b[0m\n",
      "\u001b[34m[12:44:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 24 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[19]#011train-auc:0.882799#011validation-auc:0.897233\u001b[0m\n",
      "\u001b[34m[12:44:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 24 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[20]#011train-auc:0.882799#011validation-auc:0.897233\u001b[0m\n",
      "\u001b[34m[12:44:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 24 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[21]#011train-auc:0.882799#011validation-auc:0.897233\u001b[0m\n",
      "\u001b[34m[12:44:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 24 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[22]#011train-auc:0.882799#011validation-auc:0.897233\u001b[0m\n",
      "\u001b[34m[12:44:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 24 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[23]#011train-auc:0.882799#011validation-auc:0.897233\u001b[0m\n",
      "\u001b[34m[12:44:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 24 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[24]#011train-auc:0.882799#011validation-auc:0.897233\u001b[0m\n",
      "\u001b[34m[12:44:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 24 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[25]#011train-auc:0.882799#011validation-auc:0.897233\u001b[0m\n",
      "\u001b[34m[12:44:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 24 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[26]#011train-auc:0.882799#011validation-auc:0.897233\u001b[0m\n",
      "\u001b[34m[12:44:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 24 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[27]#011train-auc:0.882799#011validation-auc:0.897233\u001b[0m\n",
      "\u001b[34m[12:44:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 24 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[28]#011train-auc:0.882799#011validation-auc:0.897233\u001b[0m\n",
      "\u001b[34m[12:44:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 24 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[29]#011train-auc:0.882799#011validation-auc:0.897233\u001b[0m\n",
      "\u001b[34m[12:44:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 24 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[30]#011train-auc:0.882799#011validation-auc:0.897233\u001b[0m\n",
      "\u001b[34m[12:44:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 24 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[31]#011train-auc:0.882799#011validation-auc:0.897233\u001b[0m\n",
      "\u001b[34m[12:44:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 24 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[32]#011train-auc:0.882799#011validation-auc:0.897233\u001b[0m\n",
      "\u001b[34m[12:44:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 24 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[33]#011train-auc:0.882799#011validation-auc:0.897233\u001b[0m\n",
      "\u001b[34m[12:44:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 24 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[34]#011train-auc:0.882799#011validation-auc:0.897233\u001b[0m\n",
      "\u001b[34m[12:44:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 24 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[35]#011train-auc:0.882799#011validation-auc:0.897233\u001b[0m\n",
      "\u001b[34m[12:44:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 24 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[36]#011train-auc:0.882799#011validation-auc:0.897233\u001b[0m\n",
      "\u001b[34m[12:44:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 24 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[37]#011train-auc:0.882799#011validation-auc:0.897233\u001b[0m\n",
      "\u001b[34m[12:44:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 24 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[38]#011train-auc:0.882799#011validation-auc:0.897233\u001b[0m\n",
      "\u001b[34m[12:44:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 24 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[39]#011train-auc:0.882799#011validation-auc:0.897233\u001b[0m\n",
      "\n",
      "2024-01-19 12:45:02 Training - Training image download completed. Training in progress.\n",
      "2024-01-19 12:45:02 Uploading - Uploading generated training model\n",
      "2024-01-19 12:45:18 Completed - Training job completed\n",
      "Training seconds: 107\n",
      "Billable seconds: 107\n"
     ]
    }
   ],
   "source": [
    "xgb.fit({'train':s3_input_train, 'validation': s3_input_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdaa579-5555-42a6-9030-ff4a9f4d56fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Start HyperParameters tunning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f3c338a0-057c-4e36-b6a9-2dd9d480f2c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating hyperparameter tuning job with name: xgboost-240119-1322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "# Define the hyperparameter ranges\n",
    "hyperparameter_ranges = {\n",
    "    'max_depth': IntegerParameter(3, 10),\n",
    "    'eta': ContinuousParameter(0.01, 0.2),\n",
    "    'min_child_weight': IntegerParameter(1, 10),\n",
    "    'subsample': ContinuousParameter(0.5, 1),\n",
    "    'gamma': ContinuousParameter(0, 5)\n",
    "}\n",
    "\n",
    "# Specify the objective metric that we'd like to tune and its definition\n",
    "objective_metric_name = 'validation:auc'  # Example metric\n",
    "objective_type = 'Maximize'  # Can be 'Maximize' or 'Minimize' depending on the metric\n",
    "\n",
    "# Configure the tuner object\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator=xgb,  # The estimator object to use as the basis for the training jobs.\n",
    "    objective_metric_name=objective_metric_name,  # The metric used to compare trained models.\n",
    "    hyperparameter_ranges=hyperparameter_ranges,  # The range of hyperparameters to tune.\n",
    "    metric_definitions=[{'Name': objective_metric_name, 'Regex': 'validation-auc:([0-9\\\\.]+)'}],  # The regex to extract the metric from the logs\n",
    "    max_jobs=20,  # The total number of models to train\n",
    "    max_parallel_jobs=3,  # The number of models to train in parallel\n",
    "    objective_type=objective_type\n",
    ")\n",
    "\n",
    "# Start the hyperparameter tuning job\n",
    "tuner.fit({'train': s3_input_train, 'validation': s3_input_test})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59516576-4977-41c9-aec5-2c14df03dfa2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Batch Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a31e577-b4f5-4160-85fd-196e3218f83d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2024-01-19 13:26:31 Starting - Preparing the instances for training\n",
      "2024-01-19 13:26:31 Downloading - Downloading the training image\n",
      "2024-01-19 13:26:31 Training - Training image download completed. Training in progress.\n",
      "2024-01-19 13:26:31 Uploading - Uploading generated training model\n",
      "2024-01-19 13:26:31 Completed - Resource reused by training job: xgboost-240119-1322-006-a2b1def2\n"
     ]
    }
   ],
   "source": [
    "best_training_job_name = 'xgboost-240119-1322-001-9a4cfdec'\n",
    "best_estimator = sagemaker.estimator.Estimator.attach(best_training_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a54ee8b-aa45-4be4-aa14-bd190be7e195",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_tuning_objective_metric': 'validation:auc',\n",
       " 'eta': '0.13077357310460885',\n",
       " 'eval_metric': 'auc',\n",
       " 'gamma': '2.2879899294244583',\n",
       " 'max_depth': '6',\n",
       " 'min_child_weight': '3',\n",
       " 'num_round': '40',\n",
       " 'objective': 'binary:logistic',\n",
       " 'subsample': '0.9725941126497504',\n",
       " 'verbosity': '1'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimator.hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61c88c04-23fe-4e36-a9da-01b69155bb6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model_transformer = best_estimator.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    output_path='s3://test-bucket-hattabi/predictions/'  # Specify your output path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0910625-f642-4edb-a386-322c6cbfbca3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating transform job with name: xgboost-2024-01-25-08-19-58-117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........................\n",
      "\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[34m[2024-01-25 08:24:30 +0000] [1] [INFO] Starting gunicorn 19.9.0\u001b[0m\n",
      "\u001b[34m[2024-01-25 08:24:30 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2024-01-25 08:24:30 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2024-01-25 08:24:30 +0000] [20] [INFO] Booting worker with pid: 20\u001b[0m\n",
      "\u001b[34m[2024-01-25 08:24:30 +0000] [21] [INFO] Booting worker with pid: 21\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)', 'urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2024-01-25:08:24:30:INFO] Model loaded successfully for worker : 20\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)', 'urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2024-01-25:08:24:30:INFO] Model loaded successfully for worker : 21\u001b[0m\n",
      "\u001b[34m[2024-01-25:08:24:35:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2024-01-25:08:24:35:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2024-01-25:08:24:35:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2024-01-25:08:24:35:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[32m2024-01-25T08:24:35.080:[sagemaker logs]: MaxConcurrentTransforms=2, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[34m[2024-01-25 08:24:30 +0000] [1] [INFO] Starting gunicorn 19.9.0\u001b[0m\n",
      "\u001b[34m[2024-01-25 08:24:30 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2024-01-25 08:24:30 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2024-01-25 08:24:30 +0000] [20] [INFO] Booting worker with pid: 20\u001b[0m\n",
      "\u001b[34m[2024-01-25 08:24:30 +0000] [21] [INFO] Booting worker with pid: 21\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)', 'urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2024-01-25:08:24:30:INFO] Model loaded successfully for worker : 20\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)', 'urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2024-01-25:08:24:30:INFO] Model loaded successfully for worker : 21\u001b[0m\n",
      "\u001b[35mArguments: serve\u001b[0m\n",
      "\u001b[35m[2024-01-25 08:24:30 +0000] [1] [INFO] Starting gunicorn 19.9.0\u001b[0m\n",
      "\u001b[35m[2024-01-25 08:24:30 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[35m[2024-01-25 08:24:30 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2024-01-25 08:24:30 +0000] [20] [INFO] Booting worker with pid: 20\u001b[0m\n",
      "\u001b[35m[2024-01-25 08:24:30 +0000] [21] [INFO] Booting worker with pid: 21\u001b[0m\n",
      "\u001b[35m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)', 'urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[35m[2024-01-25:08:24:30:INFO] Model loaded successfully for worker : 20\u001b[0m\n",
      "\u001b[35m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)', 'urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[35m[2024-01-25:08:24:30:INFO] Model loaded successfully for worker : 21\u001b[0m\n",
      "\u001b[34m[2024-01-25:08:24:35:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2024-01-25:08:24:35:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2024-01-25:08:24:35:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2024-01-25:08:24:35:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[32m2024-01-25T08:24:35.080:[sagemaker logs]: MaxConcurrentTransforms=2, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "best_model_transformer.transform(\n",
    "    data='s3://test-bucket-hattabi/train_test/test_features.csv',  # Specify your input data path\n",
    "    content_type='text/csv',  # The content type of the input data\n",
    "    split_type='Line',  # How the input data is split\n",
    ")\n",
    "best_model_transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4e048f-1c50-4ea9-ab78-88078cc553e5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0186d2cc-72f7-4f25-af41-4a7b7edea515",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "s3 = boto3.client('s3')\n",
    "# Bucket Name where the file is located\n",
    "bucket_name = 'test-bucket-hattabi'\n",
    "# Path in S3\n",
    "s3_file_key = 'predictions/test_features.csv.out'\n",
    "# Local file name to save the data\n",
    "local_file_name = 'test_features.csv.out'\n",
    "# Download the file from S3\n",
    "s3.download_file(bucket_name, s3_file_key, local_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c327d67-b564-4492-a657-4de30cf1f8d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Threshold\n",
    "threshold = 0.5\n",
    "\n",
    "# Read the probabilities from the file (assuming the file is named 'predictions.txt')\n",
    "with open('./test_features.csv.out', 'r') as file:\n",
    "    probabilities = file.readlines()\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "y_pred = [int(float(prob.strip()) >= threshold) for prob in probabilities]\n",
    "\n",
    "test = pd.read_csv(\"s3://test-bucket-hattabi/train_test/test.csv\", header=None)\n",
    "y_true = test.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f012fbaf-0b19-4295-b760-b7da30efe1ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.84       105\n",
      "           1       0.79      0.73      0.76        74\n",
      "\n",
      "    accuracy                           0.81       179\n",
      "   macro avg       0.81      0.80      0.80       179\n",
      "weighted avg       0.81      0.81      0.81       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
